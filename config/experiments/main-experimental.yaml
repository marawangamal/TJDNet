# Define reusable preamble templates
preambles:
  # Common base preamble
  base:
    - "#!/bin/bash"
    - "#SBATCH --partition=short-unkillable"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"

  # Training job preamble
  train:
    - "#SBATCH --gres=gpu:a100l:4"
    - "#SBATCH --cpus-per-task=12"
    - "#SBATCH --mem=128G"
    - "#SBATCH --time=3:00:00"

  # Evaluation job preamble  
  eval:
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --cpus-per-task=4"
    - "#SBATCH --mem=32G"
    - "#SBATCH --time=1:00:00"

  # Evaluation job preamble  
  report:
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --cpus-per-task=4"
    - "#SBATCH --mem=32G"
    - "#SBATCH --time=1:00:00"

groups:

  - name: "main-experimental"
    parallel: 
      # Run base model 
      - sequential:
        - parallellsweep:
          sweep:
            - lr:
              values: [1e-5, 5e-5, 1e-4]
          sequentialjobs:
            - job: # job_id = aaa-bbb-ccc
                preamble: train
                command: "python main.py train --accel_strategy fsdp --dataset gsm8k --model meta-llama/Llama-3.2-3B-Instruct --epochs 32 --batch_size 8 --seq_len 128 --lr {{lr}} --model_head base --rank 1 --horizon 1 --job_id {{JOB_ID}} --tag {{GROUP_NAME}}"
            - job:
                preamble: eval
                command: "python main.py test --job_id {{JOB_ID}}"
        # Choose best model base on eval_acc.py
        - job: # job_id = aaa-bbb
            preamble: eval
            command: "python scripts/tag_best_model.py --optimize_by lr --job_id {{JOB_ID}}"

      # Run cp model 
      - sequential:
        - parallellsweep:
          sweep:
            - lr:
              values: [1e-5, 5e-5, 1e-4]
            - rank:
              values: [1, 2, 4]
            - horizon:  
              values: [1, 2, 4]
          sequentialjobs:
            - job: # job_id = aaa-bbb-ccc
                preamble: train
                command: "python main.py train --accel_strategy fsdp --dataset gsm8k --model meta-llama/Llama-3.2-3B-Instruct --epochs 32 --batch_size 8 --seq_len 128 --lr {{lr}} --model_head cp --rank {{rank}} --horizon {{horizon}} --job_id {{JOB_ID}} --tag {{GROUP_NAME}}"
        
        # Choose best model base on eval_acc.py
        - job: # job_id = aaa-bbb
            preamble: eval
            command: "python scripts/tag_best_model.py --group_by rank horizon --optimize eval_loss --job_id {{JOB_ID}}"

        # Consolidate fsdp shards if needed 
        - job: # job_id = aaa-bbb
            preamble: eval
            command: "bash consolidate_ckpt.sh --job_id {{JOB_ID}}"

        # Run evaluation on the best model
        - job:
            preamble: eval
            command: "python main.py test --job_id {{JOB_ID}}"