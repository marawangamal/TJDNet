# Define reusable preamble templates
preambles:
  # Common base preamble
  base:
    - "#!/bin/bash"
    - "#SBATCH --partition=short-unkillable"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"

  # Training job preamble
  train:
    - "#SBATCH --gres=gpu:a100l:4"
    - "#SBATCH --cpus-per-task=12"
    - "#SBATCH --mem=128G"
    - "#SBATCH --time=3:00:00"

  # Evaluation job preamble  
  eval:
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --cpus-per-task=4"
    - "#SBATCH --mem=32G"
    - "#SBATCH --time=1:00:00"

  # Evaluation job preamble  
  report:
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --cpus-per-task=4"
    - "#SBATCH --mem=32G"
    - "#SBATCH --time=1:00:00"

# Root group
group:
  type: parallel
  name: "main-experimental"
  jobs:
    - group:
      type: sequential
      jobs:
        # Sweep over lr
        - group:
            type: sweep
            sweep:
              - lr: [1e-5, 5e-5, 1e-4]
              - rank: [1, 2, 4]
            jobs:
              - job: # job_id = aaa-bbb-ccc-1
                  preamble: train
                  command: "python main.py train --accel_strategy fsdp --dataset gsm8k --model meta-llama/Llama-3.2-3B-Instruct --epochs 32 --batch_size 8 --seq_len 128 --lr {{lr}} --model_head base --rank 1 --horizon 1 --job_id {{JOB_ID}} --tag {{GROUP_NAME}}"
        
        # Find best model
        - group: # job_id = aaa-bbb-ddd-1
          type: sequential
          jobs:
            - job: 
              preamble: eval
              command: "python scripts/tag_best_model.py --optimize eval_loss --job_id {{JOB_ID}} --group_id {{GROUP_ID}}"

        # Run eval on best model
        - group: # job_id = aaa-bbb-eee-1
            type: sequential
            jobs:
              - job: 
                preamble: eval
                command: "python main.py test --group_id {{GROUP_ID}} --job_id {{JOB_ID}}" 

    # # Run cp model 
    # - sequentialjobs:
    #     - parallellsweep:
    #       sweep:
    #         - lr:
    #           values: [1e-5, 5e-5, 1e-4]
    #         - rank:
    #           values: [1, 2, 4]
    #         - horizon:  
    #           values: [1, 2, 4]
    #       sequentialjobs:
    #         - job: # job_id = aaa-bbb-ccc
    #             preamble: train
    #             command: "python main.py train --accel_strategy fsdp --dataset gsm8k --model meta-llama/Llama-3.2-3B-Instruct --epochs 32 --batch_size 8 --seq_len 128 --lr {{lr}} --model_head cp --rank {{rank}} --horizon {{horizon}} --job_id {{JOB_ID}} --tag {{GROUP_NAME}}"
        
    #     # Choose best model base on eval_acc.py
    #     - job: # job_id = aaa-bbb
    #         preamble: eval
    #         command: "python scripts/tag_best_model.py --group_by rank horizon --optimize eval_loss --job_id {{JOB_ID}}"

    #     # Consolidate fsdp shards if needed 
    #     - job: # job_id = aaa-bbb
    #         preamble: eval
    #         command: "bash consolidate_ckpt.sh --job_id {{JOB_ID}}"

    #     # Run evaluation on the best model
    #     - job:
    #         preamble: eval
    #         command: "python main.py test --job_id {{JOB_ID}}"