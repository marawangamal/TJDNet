# Simplified ShareGPT experiments using base config
# This file shows how to use the new base config system with minimal overrides

preambles:
  glong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --mem=128G"
    - "#SBATCH --cpus-per-task=12"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

# Root group executed in sequence
group:
  name: "sharegpt-simplified"
  type: parallel
  jobs:

  ################################################
  #                 CP                           #  
  ################################################

    # CP experiments - only override what's different from base config
    - group:
        name: "sharegpt:cp"
        type: sequential
        jobs:
          - group:
              name: "sweep"
              type: sweep
              preamble: glong
              sweep: 
                max_num_samples: [5000]
                positivity_func: [safe_exp, sigmoid]
                horizon: [2]
              sweep_template: "python main.py fit --base_config experiments/config.yaml --trainer.max_epochs 1 --model.model lmsys/vicuna-7b-v1.5 --model.horizon {horizon} --model.rank 8 --model.model_head cp --model.positivity_func {positivity_func} --data.max_num_samples {max_num_samples} --auto_lr_find"

    # CPB experiments - simplified command line
    - group:
        name: "sharegpt:cpb"
        type: sequential
        jobs:
          - group:
              name: "sweep"
              type: sweep
              preamble: glong
              sweep: 
                max_num_samples: [5000]
                horizon: [2]
              sweep_template: "python main.py fit --base_config experiments/config.yaml --trainer.max_epochs 1 --model.model lmsys/vicuna-7b-v1.5 --model.horizon {horizon} --model.rank 8 --model.model_head cpb --data.max_num_samples {max_num_samples} --auto_lr_find"

    # Multihead experiments - simplified command line
    - group:
        name: "sharegpt:multihead"
        type: sequential
        jobs:
          - group:
              name: "sweep"
              type: sweep
              preamble: glong
              sweep: 
                max_num_samples: [5000]
                horizon: [2]
              sweep_template: "python main.py fit --base_config experiments/config.yaml --trainer.max_epochs 1 --model.model lmsys/vicuna-7b-v1.5 --model.horizon {horizon} --model.model_head multihead --data.max_num_samples {max_num_samples} --auto_lr_find" 