# test.yaml
preambles:
  glong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --mem=128G"
    - "#SBATCH --cpus-per-task=12"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

  cshort:
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long-cpu"
    - "#SBATCH --mem=32G"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

# MAIN: meta-llama/Llama-3.2-3B-Instruct
# DEBUG: distilbert/distilgpt2

# Root group executed in sequence
group:
  # aaa
  name: "main"
  type: parallel
  jobs:

  ################################################
  #                 BASE                         #  
  ################################################

    - group:
        # aaa-bbb-XXXX
        name: "countdown:stp"
        type: sweep
        preamble: glong
        sweep: 
          lr: [1e-3]
          max_num_samples: [10000]
        sweep_template:  "HF_HOME=$SCRATCH/huggingface python main.py fit --config config/config.yaml --trainer.max_epochs 10 --model.model HuggingFaceTB/SmolLM-135M --model.model_head stp --model.horizon 1 --model.rank 1 --data.batch_size 32 --data.dataset countdown --data.max_num_samples {max_num_samples} --auto_lr_find"


  ################################################
  #                 CP                           #  
  ################################################
    - group:
        # aaa-bbb-XXXX
        name: "countdown:cp"
        type: sweep
        preamble: glong
        sweep: 
          lr: [1e-3]
          max_num_samples: [10000]
          horizon: [2]
          rank: [2]
          model_head: [cp_condl, cp]
        sweep_template:  "HF_HOME=$SCRATCH/huggingface python main.py fit --config config/config.yaml --trainer.max_epochs 10 --model.model HuggingFaceTB/SmolLM-135M --model.model_head cp_condl --model.horizon {horizon} --model.rank {rank} --data.batch_size 32 --data.dataset countdown --data.max_num_samples {max_num_samples} --auto_lr_find"
