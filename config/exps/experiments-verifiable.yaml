# experiments-dcomplexity.yaml
# This file contains experiments to run on datasets with different empirical ranks 
# using MTP (Multi-Task Prediction) and STP (Single-Task Prediction) approaches
preambles:
  glong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --gres=gpu:a100l:1"
    - "#SBATCH --mem=128G"
    - "#SBATCH --cpus-per-task=12"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

  cshort:
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long-cpu"
    - "#SBATCH --mem=32G"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

# MAIN: meta-llama/Llama-3.2-3B-Instruct
# DEBUG: distilbert/distilgpt2

# Root group executed in sequence
group:
  # aaa
  name: "main"
  type: parallel
  jobs:

  ################################################
  #                 CP                           #  
  ################################################

    - group:
        # aaa-bbb
        name: "main::cp"
        type: sequential
        jobs:
          - group:
              # aaa-bbb-XXXX
              name: "sweep"
              type: sweep
              preamble: glong
              sweep: 
                horizon: [2]
                rank: [8]
                model: [meta-llama/Llama-2-7b-chat-hf]
                dataset: [aqua]
              sweep_template:  "HF_HOME=$SCRATCH/huggingface python main.py fit --config config/config.yaml --trainer.max_epochs 5 --trainer.gradient_clip_val 1.0 --model.model {model} --model.model_head cp --model.horizon {horizon} --model.rank {rank} --data.batch_size 8 --data.dataset {dataset} --auto_lr_find"



  ################################################
  #                 STP                          #  
  ################################################

    - group:
        # aaa-bbb
        name: "main::stp"
        type: sequential
        jobs:
          - group:
              name: "sweep"
              type: sweep
              preamble: glong
              sweep:
                # model: [meta-llama/Llama-2-7b-chat-hf, meta-llama/Llama-3.2-3B-Instruct]
                # dataset: [gsm8k, aqua]
                model: [meta-llama/Llama-2-7b-chat-hf]
                dataset: [aqua]
              sweep_template:  "HF_HOME=$SCRATCH/huggingface python main.py fit --config config/config.yaml --trainer.max_epochs 5 --trainer.gradient_clip_val 1.0 --model.model {model} --model.model_head stp --data.batch_size 8 --data.dataset {dataset} --auto_lr_find"



# | Model        | Dataset   | Rank (pretrained) | Rank (random) |
# |--------------|-----------|-------------------|---------------|
# | Llama-2-7B   | gsm8k     | 64.0 ± 0.0        | 1335.0 ± 0.0  |
# | Llama-2-7B   | aqua_rat  | 157.0 ± 0.0       | 1303.0 ± 0.0  |
# | Llama-2-7b   | csqa      |                   |               |
# | Llama-2-7B   | reddit    | 386.6 ± 120.1     | 1330.6 ± 14.1 |
# | Llama-2-7B   | sst2      | 687.4 ± 105.4     | 1326.2 ± 9.7  |
# | Llama-2-7B   | wikitext2 | 1071.2 ± 588.8    | 1340.2 ± 21.0 |
# | ------------------------------------------------------------ |
# | Llama-3.2-3B | gsm8k     | 109.0 ± 0.0       | 3096.0 ± 0.0  |
# | Llama-3.2-3B | aqua_rat  | 139.0 ± 0.0       | 3096.0 ± 0.0  |
# | Llama-3.2-3B | csqa      |                   |               |
# | Llama-3.2-3B | reddit    | 610.2 ± 303.3     | 3098.6 ± 5.3  |
# | Llama-3.2-3B | sst2      | 1139.6 ± 204.3    | 3102.4 ± 5.3  |
# | Llama-3.2-3B | wikitext2 | 1307.0 ± 266.7    | 3102.0 ± 6.8  |