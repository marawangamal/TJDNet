# test.yaml
preambles:
  gpu1:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --gres=gpu:rtx8000:1"
    - "#SBATCH --mem=32G"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

  cpu:
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=unkillable-cpu"
    - "#SBATCH --mem=8G"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

  cpulong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --mem=32G"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/tjdnet/.venv/bin/activate"

# Root group executed in sequence
group:
  # aaa
  name: "deff"
  type: parallel
  jobs:

    # CP with varying dataset size
    - group:
        # aaa-bbb
        name: "deff:cp"
        type: sequential
        jobs:
          #  1. Sweep over lr, rank, horizon
          # aaa-bbb-aaa-XXXX
          - group:
              type: parallel
              name: "sweep"
              jobs:
                - group:
                    type: sweep
                    preamble: gpu1
                    sweep: # 48x5=240
                      lr: [1e-2, 5e-3, 1e-3, 5e-4, 1e-4]
                      rank: [2, 8, 16, 32]
                      horizon: [2, 4, 8]
                      max_num_samples: [50, 100, 200, 500]
                    sweep_template:  "python main.py train --dataset stemp --model gpt2 --epochs 55 --batch_size 8 --seq_len 128 --lr {lr} --model_head cp --rank {rank} --horizon {horizon} --use_memory_efficient_loss --slurm_job_id $SLURM_JOB_ID --group_id {group_id} --max_num_samples {max_num_samples} --delete_ckpt"

          # 2. Tag best model for each (rank, horizon) combination
          # aaa-bbb-bbb
          - job:
              # Creates a <experiment_name>/.prospect file
              preamble: cpu
              command: "python main.py tag --group_by rank horizon max_num_samples --group_level 1 --group_id {group_id}"
              name: "tag"
      

          # 3. Run training/testing on best models
          # aaa-bbb-ccc-XXXX
          - group:
              type: loop
              name: "loop"
              loop_count: 48
              loop_type: "parallel"
              jobs:
                - group:
                    type: sequential
                    jobs:
                      # aaa-bbb-ccc-aaa
                      # Creates a <experiment_name>/.best file
                      - job:
                          preamble: gpu1
                          command: "python main.py train --lookup --epochs 300  --group_level 1 --group_id {group_id} --idx {loop_idx}"
                          name: "ltrain"

                      # Run expensive test on best models
                      # aaa-bbb-ccc-bbb
                      - job:
                          preamble: gpu1
                          command: "python main.py test --lookup --group_level 1 --group_id {group_id} --idx {loop_idx} --delete_ckpt --gen_mode draft_multi_horizon" 
                          name: "ltest"


    # # BASE with varying dataset size
    # - group:
    #     # aaa-bbb
    #     name: "deff:base"
    #     type: sequential
    #     jobs:
    #       # aaa-bbb-aaa-XXXX
    #       - group:
    #           type: parallel
    #           name: "sweep"
    #           jobs:
    #             - group:
    #                 type: sweep
    #                 preamble: gpu1
    #                 sweep: # 3x1x5=15
    #                   lr: [1e-3]
    #                   max_num_samples: [50, 100, 200, 500]
    #                 sweep_template:  "python main.py train --dataset stemp --model gpt2 --epochs 300 --batch_size 8 --seq_len 128 --lr {lr} --model_head base --rank 1 --horizon 1 --use_memory_efficient_loss --slurm_job_id $SLURM_JOB_ID --group_id {group_id} --max_num_samples {max_num_samples} --gen_mode draft_multi_horizon --compute_acc --delete_ckpt"

