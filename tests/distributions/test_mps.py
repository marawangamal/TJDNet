import unittest
import torch

from tjdnet.distributions._tjdist import BaseDistConfig
from tjdnet.distributions.mps import MPSDist
from tjdnet.distributions.tpnet import TensorParamNetConfig


class TestMPSDist(unittest.TestCase):

    def test_select_from_cp_tensor(self):
        batch_size, seq_len, vocab_size, rank, horizon, n_embd = (
            8,
            128,
            50265,
            2,
            3,
            768,
        )
        eps = 1e-9

        model_head = MPSDist(
            BaseDistConfig(
                vocab_size=vocab_size,
                horizon=horizon,
                rank=rank,
                param_net=TensorParamNetConfig(
                    in_dim=n_embd,
                    out_dim_encoder=horizon * rank * rank,
                    out_dim_decoder=vocab_size,
                ),
            )
        )

        for i in range(10):
            last_hidden_state = torch.randn(batch_size, seq_len, n_embd)
            targets = torch.randint(0, vocab_size, (batch_size, seq_len, horizon))

            p_tilde, p_tilde_scale_factors, norm_const, norm_const_scale_factors = (
                model_head.evaluate_at_points_and_get_norm_consts(
                    last_hidden_state, targets
                )
            )  # (B, T-H)

            loss = (
                -torch.log(p_tilde + eps)  # (B, T')
                + torch.log(norm_const)  # (B, T')
                # Contraction Stability Scale Factors
                - sum([torch.log(z) for z in p_tilde_scale_factors])  # (B, T')
                + sum([torch.log(z) for z in norm_const_scale_factors])
            )  # (B, T-H)

            loss = loss.sum(dim=-1).mean()
            # self.assertLess(loss.item(), 1e3)

            # Loss should be non-negative
            self.assertGreaterEqual(loss.item(), 0)


if __name__ == "__main__":
    unittest.main()


# targets
# [  220, 22074,    37]

# last_hidden_state[5][1]
# tensor([ 2.0111e-01, -6.4697e-01,  8.1568e-01,  2.8605e-01, -1.4877e-01,
#         -4.2421e-01,  5.0655e+00, -2.8446e-01, -3.0576e-02,  1.9816e-02,
#         -5.4321e-01, -2.3249e-01, -7.4844e-01,  1.9913e-01,  7.9222e-01,
#         -8.1285e-02, -7.4696e-01, -2.6915e-02,  1.2734e+00,  4.8963e-01,
#          2.3157e-01,  2.8890e-01, -4.5573e-01,  8.0237e-01, -7.0812e-01,
#          3.2860e-01,  1.0450e+00, -3.8864e-01, -6.7949e-01,  7.7666e-03,
#         -1.4588e+00,  3.0630e-01,  5.0099e-01, -7.4681e-01, -1.0579e+00,
#          2.0777e-01,  6.5416e+01,  9.9264e-01, -5.2596e-01,  7.4567e-02,
#          3.6843e-01,  5.2910e-01,  6.3506e-01, -2.9996e-01, -8.8098e-02,
#          4.7373e-01, -1.3395e-01, -4.6642e-01, -4.3093e-02,  5.3368e-01,
#          2.4174e-01, -1.7385e-01,  4.9629e-01,  1.5575e-01, -2.9124e-01,
#          1.4803e+00,  4.8090e-01, -2.9575e-01, -1.3027e-01, -1.1204e-01,
#         -3.0438e-01,  3.6382e-01,  4.8754e-01, -3.8909e-01, -1.0993e+00,
#         -3.2886e-01,  1.5686e-01, -3.3571e-01, -9.0462e-01, -3.8248e-01,
#         -6.6247e-02, -2.5912e-01, -2.2688e-02, -3.7673e-01, -3.4592e-01,
#         -9.4478e-03, -6.8918e-01, -4.3007e+00,  3.3283e-01, -8.0180e-01,
#         -2.3536e-02,  5.4007e-01,  5.1684e-01, -9.4769e-01, -2.3843e-01,
#          9.9273e-01,  9.5171e-01, -1.0157e+00,  5.3281e-01, -3.9461e-01,
#          2.1410e-01,  1.1757e-01, -8.2142e-01, -8.0400e-01,  3.0550e-01,
#         -1.6638e-01,  1.2921e-01, -1.1874e-01,  4.0332e-01,  4.3668e-01,
#         -6.4935e-01,  4.2416e-01, -1.5442e+00,  6.6426e-01, -3.0635e-01,
#         -6.1180e-02,  1.0132e-01,  1.0424e+01,  3.1540e-02, -2.8808e-01,
#         -5.1854e-01, -1.0731e+00, -7.6984e-01,  2.9848e-01, -1.0686e+00,
#          5.1317e-01,  1.4294e+00, -8.7770e-01, -1.9073e-01,  3.7752e-01,
#          6.1785e-01,  1.3219e+00, -4.8628e-01, -1.2737e-01, -1.2527e-01,
#          3.0327e-01,  4.9082e-01, -1.8054e-01,  1.1269e-01, -4.3562e-01,
#         -9.7017e-02, -7.8385e-01,  7.7933e-01,  2.0904e-01,  2.9060e-01,
#          1.0347e+00, -1.1020e+00,  1.0185e+00,  4.3800e-01,  1.2595e-01,
#         -1.0925e+00, -1.6772e-01,  1.2302e-01, -4.6177e-01, -1.4377e-01,
#         -3.9441e-01, -4.4395e-01, -3.5441e-02, -4.0082e-01, -1.7411e-02,
#          1.7956e-01,  9.1739e-02, -1.1999e+00,  1.4433e-01,  3.0606e-01,
#         -3.7043e-01,  6.3145e-01, -5.0110e-02,  1.7074e-01, -1.0432e+00,
#         -6.6155e-01, -4.0815e-01,  1.2096e+00,  2.8086e-01,  2.0608e-01,
#         -4.8188e-01, -2.1984e-02,  5.5711e-01,  6.0832e-01, -2.8303e-01,
#          1.9218e-01, -1.4108e-01, -9.1575e-03,  7.1348e-01,  1.1704e+00,
#          7.0996e-01,  1.0518e+00,  3.4737e-01,  3.1626e-01, -3.5016e-01,
#         -3.0102e-02,  1.3796e+00, -1.1682e+00,  2.1603e-01,  7.4516e-01,
#          1.1647e-01,  7.2631e-01,  6.0081e-02, -2.5111e-01, -5.1614e-02,
#         -2.6129e-01, -3.7105e-01, -4.7121e-02,  5.7903e-01,  3.0332e-01,
#         -1.3775e+00,  2.0075e-01,  6.9214e-01, -6.7734e-01,  2.7888e-01,
#         -1.0234e+00,  2.4302e-01, -4.8062e-01,  2.8447e-01, -2.4693e-01,
#         -3.0151e-01,  4.5810e-01, -3.0997e-01,  1.7352e-02, -4.4931e-01,
#          4.4652e-01, -8.4917e-01, -1.0447e+00,  3.4972e-01, -7.4870e-01,
#         -1.4737e-01, -5.3259e-02, -4.4677e-01, -7.9382e-01, -4.1867e-01,
#          3.1776e-01,  4.9974e-01, -5.8722e-01,  3.6621e-01,  4.2266e-02,
#          5.8774e-01, -1.7045e-01,  6.6615e-01, -2.2620e-02,  1.1188e+00,
#          2.6928e-02, -1.9322e-01, -3.0484e-04, -3.6186e-01, -5.8444e-01,
#         -7.3575e-01, -3.6163e-01, -2.4392e-01,  5.8447e-02, -7.3068e-01,
#          4.7374e-01, -1.7305e-01,  1.0220e-01, -7.1090e-02,  3.0695e-01,
#          8.5512e-02, -2.3205e-01,  3.1371e-01,  1.2272e+00, -4.3693e-01,
#         -2.1988e+00,  7.0799e-02,  8.6346e-01,  8.0014e-01,  6.8554e-01,
#         -1.4424e-01,  1.2609e+00, -4.4284e-02, -2.6560e-01,  4.3971e-01,
#         -8.4054e-01,  5.5043e-02,  4.8325e-02, -1.5256e-02, -4.0316e-01,
#         -5.1195e-01, -9.8525e-01, -3.9571e-01, -3.4263e-02, -5.0536e-02,
#          6.3013e-01, -5.1003e-01,  6.1742e-01,  8.4521e-01,  8.8682e-01,
#         -6.9360e-01, -9.5612e-01,  1.8465e-01, -7.7914e-02, -6.1054e-01,
#          7.7806e-01, -9.5433e-01,  1.3959e-01, -7.1674e-01,  4.9075e-01,
#          5.1652e-01,  3.6480e-01, -3.6465e-01, -7.1858e-01,  5.5165e-01,
#         -3.7134e-01, -5.6372e-01, -3.1290e-02,  6.9034e-01, -5.7168e-02,
#         -1.9210e-01,  1.8090e-01,  1.5520e-01, -7.9653e-01, -9.0796e-01,
#         -1.1265e+00,  5.6150e-01, -2.5576e-01,  1.6271e-01,  3.9462e-01,
#         -2.9140e-01, -4.9397e-01, -9.4125e-02,  7.3548e-01,  5.3223e-01,
#          8.3490e-01,  1.4405e+00,  5.3960e-01, -1.7772e+00,  2.8238e+00,
#         -1.8853e-01, -8.2555e-02,  3.8811e-01, -2.7769e-01,  7.5662e-01,
#         -9.5931e-01, -1.8865e-01,  9.6610e-02, -1.0821e+00, -2.2988e-01,
#         -2.6574e-01, -1.0999e+00,  4.1864e-01,  1.1698e-01, -1.8226e-01,
#         -1.3759e-01, -1.7439e+00,  6.2238e-01,  1.2661e-01,  1.1403e-01,
#          1.8388e-01,  4.9660e-01, -9.9587e-02, -2.7383e-01, -2.6710e-01,
#          1.3696e-01,  1.2124e-02, -3.5756e-01, -7.8187e-01, -4.2577e-01,
#          5.2471e-01, -1.0404e-01, -2.9146e-02, -1.5868e-01,  2.8040e-01,
#         -3.0428e-01, -4.6063e-01,  5.2186e-01, -1.1457e-01,  5.3923e-01,
#         -5.0566e-01, -9.6964e-01, -1.6333e-01,  5.8464e-01, -6.0678e-01,
#          4.2159e-01,  1.6455e+00, -5.6662e-01, -7.8024e-01,  8.8045e-01,
#          1.6641e+00,  1.2972e-01,  1.7371e-01,  1.5933e-01, -3.7626e-01,
#          8.9586e-01, -5.8543e-01,  6.8217e-01, -1.2252e+00, -8.1728e+00,
#         -1.8095e-01,  1.5819e-02, -4.8546e-01,  2.1850e-01, -4.2978e-01,
#          1.0449e+00,  2.1663e-01, -1.1871e+00,  5.1015e-01,  3.5004e-01,
#          1.8448e-01, -1.1159e-01,  1.9808e-01, -5.4073e-01,  1.7494e-01,
#          2.0356e-01, -2.5780e-01,  9.4928e-02, -5.8050e-02,  8.9462e-01,
#         -4.0545e-01, -1.6407e+00,  3.1879e-01, -8.1108e-01, -3.3676e-01,
#          1.6101e-01,  1.3167e-01,  9.5577e-01,  1.1269e-01,  1.5181e-01,
#          7.1798e-01, -6.9176e-01, -3.1759e-01, -1.2505e-01, -4.9920e-01,
#          2.4685e-01,  6.4656e-01, -7.5202e-02, -2.9055e-01,  3.8102e-01,
#         -3.5700e-01,  1.0780e+00, -2.3529e-01, -1.2029e+00, -3.8053e-01,
#         -1.9140e+00, -4.7282e-01,  1.7761e-01, -8.9509e-02,  1.3894e-01,
#         -2.7770e-01,  3.4650e-01, -4.1927e-02, -2.2197e-01, -7.6050e-02,
#          8.7299e+01, -5.9541e-01, -1.6693e-02,  7.3556e-02,  1.1264e-01,
#          2.4491e-01,  3.1548e-01,  7.6814e-01,  5.0815e-01,  1.3619e+00,
#          6.1541e-01,  1.0395e-01,  5.5922e+00,  1.7038e-01,  7.9256e-01,
#         -9.0013e-01,  4.3309e-01,  1.1356e+00,  1.5687e-02, -5.7594e-01,
#          8.6989e-01, -2.5078e-01,  1.7756e-01, -2.2854e+00, -4.2633e-01,
#          1.5271e+00, -3.7811e-02, -5.3016e-01, -3.3260e-01, -1.9297e+00,
#          7.4616e-01, -2.3084e-01, -2.1978e-01, -1.0353e+00,  1.3399e+00,
#         -1.0040e+00, -4.2094e-01, -9.9495e-01,  6.7059e-01,  3.7258e-02,
#          8.8848e-01, -3.4189e-01, -3.1383e-01,  1.5750e-01, -6.8893e-01,
#          1.4998e-01, -4.3026e-01, -8.7475e-01,  8.9928e-01, -2.4556e+00,
#         -8.7923e-01,  1.2651e+00,  1.9228e-01, -1.0850e-01,  1.1342e+00,
#         -1.2820e-01,  1.8385e-01,  6.4488e-01, -2.4528e-03, -6.1603e-02,
#         -2.9719e-01,  2.5607e-01,  6.1170e-01, -4.8243e-02, -1.1096e-01,
#         -5.5382e-01,  1.5490e+02,  6.2137e-02, -8.1650e-01, -1.9207e-01,
#          6.2284e-02, -5.1704e-01,  3.1007e-01, -1.1842e+00, -7.9755e-02,
#          1.3257e-01, -5.0522e-02,  1.8249e-01, -6.4061e-02, -1.4654e-01,
#          5.0788e-01,  2.7298e-01,  2.8620e-01, -3.0752e-01,  5.0425e-02,
#          4.6347e-01, -4.2592e-01,  1.0182e+00,  8.6167e-02, -4.3092e-01,
#          2.6718e-01, -5.9054e-01,  3.0940e-02, -1.2664e-01, -4.1922e-01,
#          4.7237e-01, -1.9240e-01, -2.7441e-02, -8.4631e-01, -5.8608e-01,
#         -6.7323e-01,  8.7188e-02,  2.9718e-01, -6.1395e-01,  2.5101e-02,
#         -5.3883e-01,  1.0040e+00, -4.5298e-01, -1.2433e+00,  6.0315e-01,
#         -4.7875e-02,  1.1576e-01, -3.8946e-01,  2.1336e+00, -6.9938e-01,
#          1.0837e+00, -7.2413e-01, -1.5012e-01, -1.0618e+00,  7.0284e-01,
#          7.4903e-01,  1.2078e+00, -1.5398e-01,  6.2907e-01, -3.4606e+00,
#         -8.7740e-01,  4.7347e-01,  6.7452e-01, -5.1244e-01, -4.1744e-01,
#          3.6818e-01,  1.7297e-02,  6.2611e-01, -3.4546e-01, -5.6610e-01,
#          1.1894e-01,  9.1742e-02, -1.0668e+00,  7.2054e-01, -1.8958e-01,
#          7.6889e-01, -6.3201e-02, -1.1782e+00, -6.8985e-01, -1.1387e+00,
#          8.5888e-01, -3.3603e-01,  4.9788e-01, -3.4812e-01,  4.3051e-02,
#         -6.6193e-01,  2.8044e-02, -6.5559e-02,  3.5159e-01, -2.9415e-01,
#         -8.4663e-02, -1.3230e-01, -1.0163e+00, -9.5895e-01, -4.5914e-01,
#          1.0617e-01,  2.9216e-02,  3.3311e-02,  1.2446e+00, -4.5847e-01,
#          6.5167e-01, -3.3376e-01,  1.4246e-02, -2.0593e-01,  6.7641e-01,
#         -1.2683e+00,  2.4574e-01,  2.5332e-01,  5.9948e-01,  2.1781e-01,
#          2.1586e-01,  5.0890e-01,  4.7018e-01, -3.1947e-01,  1.1604e+00,
#         -5.2522e-03,  6.6107e-01, -1.7433e-02,  3.2313e-01, -6.5313e-01,
#          3.9227e-01, -3.0434e-04, -1.0580e-01,  2.0751e-01,  7.3340e-01,
#          3.7914e-01,  1.1819e+00,  6.8986e-01, -3.5414e+00,  2.5578e-02,
#          1.2508e+00,  9.0820e-02,  7.4739e-01, -6.0382e-01,  2.2491e-01,
#          2.8062e-01, -8.0321e-01, -4.4794e-01,  2.8314e-01, -6.8871e-02,
#          9.1489e-01, -2.2729e-01,  6.6918e-01, -9.3281e-02,  1.3881e-01,
#         -1.1819e+00, -6.6126e-01,  4.2265e-02,  3.0320e-01,  4.5745e-01,
#         -7.8141e-01, -1.4684e-01, -4.2339e-01, -1.0026e+00, -1.7149e+00,
#         -6.1590e-02,  5.5257e-01, -4.3453e-01, -2.5861e-01,  6.9717e-01,
#         -7.0172e-01,  3.5245e-01, -8.0095e-02,  1.8976e-02, -3.8235e-01,
#         -2.9068e-01,  3.3072e-01,  3.7718e-01, -4.9419e-02,  5.8831e-01,
#         -1.9788e-01,  7.6500e-03, -2.5380e-01,  1.1962e-01, -4.8801e-01,
#         -1.3205e+00, -4.2204e-01,  4.8509e-01, -2.2532e-01, -2.2996e-01,
#          3.9435e-01, -2.1705e-01, -1.2922e-01, -4.8461e-01,  1.2588e+00,
#          2.7775e-01,  4.6727e-01, -6.4653e-01,  4.1507e-01,  3.8714e-01,
#         -6.0815e-01, -5.1715e-01,  1.0251e-01,  1.0090e+00, -9.4248e-01,
#          9.9240e-01,  3.4463e-02, -1.0203e+00, -1.1895e-01, -2.3025e-01,
#          2.7804e-01,  2.6954e-01, -8.0978e-01,  9.3402e-01,  1.3441e-01,
#          1.0373e-01, -3.1568e-02,  3.2474e-01, -1.8112e+01, -5.3244e-01,
#          6.2350e-02,  1.6266e+00,  4.4252e-01, -6.9453e-01,  1.4284e-02,
#         -2.6771e-01, -1.0549e-01,  4.5161e-01,  5.2121e-01,  8.5714e-02,
#         -4.6182e-01,  3.4864e-02,  4.3294e-02, -2.4038e+00, -9.5769e-01,
#          2.8497e-01,  3.1352e-01,  3.1157e-01,  7.8345e-02,  2.7011e+00,
#          2.0275e-01,  4.6892e-01,  5.6666e-03,  3.0872e-02,  1.9398e-01,
#          9.5353e-01,  9.6809e-02, -3.1863e-01,  2.3085e-01, -2.0120e-01,
#         -7.8698e-01,  8.3897e-01, -4.9629e-01, -1.3009e-02,  4.3710e-01,
#          2.5969e-01, -1.4358e-01, -7.9516e-02,  7.1742e-01,  7.3284e-01,
#         -5.4231e-01, -7.4972e-01,  3.2142e-01, -2.9390e-02, -1.7850e+00,
#         -1.3704e+00, -4.6040e-01, -2.8238e-01, -3.4052e-01,  3.8668e-01,
#          6.3701e-01,  4.4688e-01,  1.1842e-02,  7.6804e-01,  2.7924e-01,
#          1.4478e-01, -4.7390e-01, -1.6263e+00, -5.9609e-01, -5.7576e-01,
#          2.7841e-01, -5.7001e-01, -2.6590e-01], device='cuda:1',
#        grad_fn=<SelectBackward0>)


# self.model_head.param_func.w.weight
# tensor([[ 0.0160,  0.0199,  0.0040,  ...,  0.0034,  0.0110, -0.0333],
#         [-0.0015, -0.0342,  0.0340,  ..., -0.0051, -0.0227, -0.0010],
#         [-0.0359, -0.0377, -0.0019,  ...,  0.0366, -0.0282,  0.0046],
#         ...,
#         [-0.0032, -0.0098,  0.0148,  ..., -0.0203, -0.0193, -0.0348],
#         [ 0.0235, -0.0152, -0.0171,  ..., -0.0086, -0.0197,  0.0333],
#         [ 0.0308,  0.0067,  0.0310,  ...,  0.0152,  0.0224, -0.0005]],


# self.model_head.param_func.w.bias
# tensor([-0.0030, -0.0213, -0.0049,  ..., -0.0009, -0.0151, -0.0118],
#        device='cuda:1', grad_fn=<BroadcastBackward>)


# vs on start


# self.model_head.param_func.w.weight
# tensor([[ 0.0174,  0.0200,  0.0029,  ...,  0.0053,  0.0096, -0.0334],
#         [-0.0019, -0.0345,  0.0326,  ..., -0.0048, -0.0234, -0.0005],
#         [-0.0350, -0.0354, -0.0005,  ...,  0.0356, -0.0293,  0.0031],
#         ...,
#         [-0.0051, -0.0111,  0.0126,  ..., -0.0191, -0.0176, -0.0330],
#         [ 0.0236, -0.0142, -0.0152,  ..., -0.0095, -0.0188,  0.0328],
#         [ 0.0298,  0.0081,  0.0296,  ...,  0.0168,  0.0213,  0.0015]],
#        device='cuda:0', grad_fn=<BroadcastBackward>)
# self.model_head.param_func.w.bias
# tensor([-0.0016, -0.0201, -0.0050,  ...,  0.0012, -0.0160, -0.0127],
#        device='cuda:0', grad_fn=<BroadcastBackward>)
