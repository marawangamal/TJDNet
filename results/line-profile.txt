BASE
Total time: 0.962661 s
File: /Users/marawangamal/Documents/github/TJDNet/models/tjdgpt2/tjdgpt2.py
Function: forward at line 223
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   223                                               @line_profiler.profile
   224                                               def forward(
   225                                                   self,
   226                                                   input_ids: torch.Tensor,
   227                                                   labels: torch.Tensor,
   228                                                   horizon: Optional[int] = None,
   229                                                   reduce="mean",
   230                                                   use_memory_efficient_loss: bool = False,
   231                                                   **kwargs,
   232                                               ) -> Dict[str, torch.Tensor]:
   233                                                   """Forward pass of the model.
   234                                           
   235                                                   Args:
   236                                                       input_ids (torch.Tensor): Tensor of shape (B, T)
   237                                                       labels (torch.Tensor): Tensor of shape (B, T)
   238                                                       horizon (Optional[int], optional): Joint distribution size. If None, uses the model level horizon. Defaults to None.
   239                                           
   240                                                   Note:
   241                                                       The horizon applied in the forward pass is the minimum of the model level horizon and the horizon passed as an argument.
   242                                           
   243                                                   Returns:
   244                                                       torch.Tensor: Loss value.
   245                                                   """
   246                                           
   247                                                   # Sequence length must be greater than horizon
   248         2          1.0      0.5      0.0          assert (
   249         2          4.0      2.0      0.0              input_ids.size(1) > self.horizon
   250                                                   ), "Sequence length must be greater than horizon"
   251                                           
   252         2          2.0      1.0      0.0          batch_size, _ = input_ids.size()
   253         2          4.0      2.0      0.0          horizon = self._get_horizon(horizon)
   254                                           
   255         2     579238.0 289619.0     60.2          last_hidden_state = self._get_last_hidden_state(input_ids)
   256         4       1763.0    440.8      0.2          targets = get_windowed_input_ids(input_ids, horizon=horizon).reshape(
   257         2          0.0      0.0      0.0              batch_size, -1, horizon
   258                                                   )  # (B, T-H, H)
   259                                           
   260         2          2.0      1.0      0.0          assert targets.size(1) >= horizon, "Invalid targets"
   261                                           
   262         2        156.0     78.0      0.0          last_hidden_state_ds = last_hidden_state[:, :-horizon]  # (B, T-H, D)
   263         2          0.0      0.0      0.0          targets_ds = targets  # (B, T-H, H)
   264         2          0.0      0.0      0.0          if use_memory_efficient_loss:
   265                                                       # Downsample hidden states and targets
   266                                                       last_hidden_state_ds = last_hidden_state_ds[:, ::horizon]
   267                                                       targets_ds = targets[:, ::horizon]
   268                                           
   269         4     192091.0  48022.8     20.0          p_tilde, p_tilde_scale_factors = self.model_head.evaluate_at_points(
   270         2          0.0      0.0      0.0              last_hidden_state_ds, targets_ds
   271                                                   )  # (B, T-H)
   272                                           
   273         4     184731.0  46182.8     19.2          norm_const, norm_const_scale_factors = self.model_head.get_norm_consts(
   274         2          0.0      0.0      0.0              last_hidden_state_ds, horizon=horizon
   275                                                   )  # (B, T-H)
   276                                           
   277                                                   # Health checks
   278                                                   # 1. Ensure no NaNs
   279         2       1098.0    549.0      0.1          assert not torch.isnan(p_tilde).any(), "p_tilde NaN"
   280         2         11.0      5.5      0.0          assert not torch.isnan(norm_const).any(), "norm_const NaN"
   281                                                   # 2. Ensure p_tilde < norm_const (if no scale factors)
   282         2          3.0      1.5      0.0          if len(p_tilde_scale_factors) == 0 and len(norm_const_scale_factors) == 0:
   283         2       1110.0    555.0      0.1              assert (p_tilde < norm_const).all(), "p_tilde < norm_const"
   284                                           
   285         2          0.0      0.0      0.0          loss = (
   286         8       1743.0    217.9      0.2              -torch.log(p_tilde + self.eps)
   287         2          8.0      4.0      0.0              + torch.log(norm_const)
   288                                                       # Contraction Stability Scale Factors
   289         2          6.0      3.0      0.0              - sum([torch.log(z) for z in p_tilde_scale_factors])
   290         2          2.0      1.0      0.0              + sum([torch.log(z) for z in norm_const_scale_factors])
   291                                                   )  # (B, T-H)
   292                                           
   293                                                   # Train loss
   294         2         29.0     14.5      0.0          nll = loss[:, ::horizon]  # batch and seq mean of negative log likelihood
   295         4          4.0      1.0      0.0          reduct_fn = {
   296         2          3.0      1.5      0.0              "mean": torch.mean,
   297         2          1.0      0.5      0.0              "sum": torch.sum,
   298         2          0.0      0.0      0.0              "none": lambda x: x,
   299         2          1.0      0.5      0.0          }[reduce]
   300         2          1.0      0.5      0.0          return {
   301         2        592.0    296.0      0.1              "loss": reduct_fn(loss.sum(dim=-1)),
   302         2         17.0      8.5      0.0              "nll": reduct_fn(nll.sum(dim=-1)),
   303         2         40.0     20.0      0.0              "loss_scale": torch.tensor(1 / self.rank).to(loss.device),


Total time: 1.92557 s
File: /Users/marawangamal/Documents/github/TJDNet/models/tjdgpt2/tjdgpt2.py
Function: forward at line 223

CP

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   223                                               @line_profiler.profile
   224                                               def forward(
   225                                                   self,
   226                                                   input_ids: torch.Tensor,
   227                                                   labels: torch.Tensor,
   228                                                   horizon: Optional[int] = None,
   229                                                   reduce="mean",
   230                                                   use_memory_efficient_loss: bool = False,
   231                                                   **kwargs,
   232                                               ) -> Dict[str, torch.Tensor]:
   233                                                   """Forward pass of the model.
   234                                           
   235                                                   Args:
   236                                                       input_ids (torch.Tensor): Tensor of shape (B, T)
   237                                                       labels (torch.Tensor): Tensor of shape (B, T)
   238                                                       horizon (Optional[int], optional): Joint distribution size. If None, uses the model level horizon. Defaults to None.
   239                                           
   240                                                   Note:
   241                                                       The horizon applied in the forward pass is the minimum of the model level horizon and the horizon passed as an argument.
   242                                           
   243                                                   Returns:
   244                                                       torch.Tensor: Loss value.
   245                                                   """
   246                                           
   247                                                   # Sequence length must be greater than horizon
   248         2          0.0      0.0      0.0          assert (
   249         2         10.0      5.0      0.0              input_ids.size(1) > self.horizon
   250                                                   ), "Sequence length must be greater than horizon"
   251                                           
   252         2          2.0      1.0      0.0          batch_size, _ = input_ids.size()
   253         2         16.0      8.0      0.0          horizon = self._get_horizon(horizon)
   254                                           
   255         2     457729.0 228864.5     23.8          last_hidden_state = self._get_last_hidden_state(input_ids)
   256         4        300.0     75.0      0.0          targets = get_windowed_input_ids(input_ids, horizon=horizon).reshape(
   257         2          0.0      0.0      0.0              batch_size, -1, horizon
   258                                                   )  # (B, T-H, H)
   259                                           
   260         2          2.0      1.0      0.0          assert targets.size(1) >= horizon, "Invalid targets"
   261                                           
   262         2         14.0      7.0      0.0          last_hidden_state_ds = last_hidden_state[:, :-horizon]  # (B, T-H, D)
   263         2          1.0      0.5      0.0          targets_ds = targets  # (B, T-H, H)
   264         2          0.0      0.0      0.0          if use_memory_efficient_loss:
   265                                                       # Downsample hidden states and targets
   266                                                       last_hidden_state_ds = last_hidden_state_ds[:, ::horizon]
   267                                                       targets_ds = targets[:, ::horizon]
   268                                           
   269         4     664416.0 166104.0     34.5          p_tilde, p_tilde_scale_factors = self.model_head.evaluate_at_points(
   270         2          1.0      0.5      0.0              last_hidden_state_ds, targets_ds
   271                                                   )  # (B, T-H)
   272                                           
   273         4     802621.0 200655.2     41.7          norm_const, norm_const_scale_factors = self.model_head.get_norm_consts(
   274         2          1.0      0.5      0.0              last_hidden_state_ds, horizon=horizon
   275                                                   )  # (B, T-H)
   276                                           
   277                                                   # Health checks
   278                                                   # 1. Ensure no NaNs
   279         2         91.0     45.5      0.0          assert not torch.isnan(p_tilde).any(), "p_tilde NaN"
   280         2         10.0      5.0      0.0          assert not torch.isnan(norm_const).any(), "norm_const NaN"
   281                                                   # 2. Ensure p_tilde < norm_const (if no scale factors)
   282         2          2.0      1.0      0.0          if len(p_tilde_scale_factors) == 0 and len(norm_const_scale_factors) == 0:
   283         2         65.0     32.5      0.0              assert (p_tilde < norm_const).all(), "p_tilde < norm_const"
   284                                           
   285         2          0.0      0.0      0.0          loss = (
   286         8        126.0     15.8      0.0              -torch.log(p_tilde + self.eps)
   287         2          6.0      3.0      0.0              + torch.log(norm_const)
   288                                                       # Contraction Stability Scale Factors
   289         2         15.0      7.5      0.0              - sum([torch.log(z) for z in p_tilde_scale_factors])
   290         2          2.0      1.0      0.0              + sum([torch.log(z) for z in norm_const_scale_factors])
   291                                                   )  # (B, T-H)
   292                                           
   293                                                   # Train loss
   294         2         22.0     11.0      0.0          nll = loss[:, ::horizon]  # batch and seq mean of negative log likelihood
   295         4          3.0      0.8      0.0          reduct_fn = {
   296         2          1.0      0.5      0.0              "mean": torch.mean,
   297         2          1.0      0.5      0.0              "sum": torch.sum,
   298         2          1.0      0.5      0.0              "none": lambda x: x,
   299         2          0.0      0.0      0.0          }[reduce]
   300         2          2.0      1.0      0.0          return {
   301         2         51.0     25.5      0.0              "loss": reduct_fn(loss.sum(dim=-1)),
   302         2         13.0      6.5      0.0              "nll": reduct_fn(nll.sum(dim=-1)),
   303         2         42.0     21.0      0.0              "loss_scale": torch.tensor(1 / self.rank).to(loss.device),
   304                                                   }