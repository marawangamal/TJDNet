python eval_latency.py --device cuda --inp_seq_len 256 --out_seq_len 128


Benchmark Results:
--------------------------------------------------

gpt2:
Mean latency: 1.375s ± 0.044s
Min: 1.326s | Max: 1.457s
GPU memory (allocated): 1100.37 MB ± 0.00 MB
CPU memory (RSS): 1051.36 MB ± 0.00 MB

gpt2::cp::rank1::horizon1:
Mean latency: 1.623s ± 0.074s
Min: 1.536s | Max: 1.748s
GPU memory (allocated): 1492.63 MB ± 3.05 MB
CPU memory (RSS): 1081.63 MB ± 0.01 MB

gpt2::cp::rank2::horizon2:
Mean latency: 1.084s ± 0.060s
Min: 0.998s | Max: 1.179s
GPU memory (allocated): 2526.00 MB ± 2.35 MB
CPU memory (RSS): 1476.59 MB ± 0.00 MB

gpt2::cp::rank4::horizon4:
Mean latency: 0.726s ± 0.075s
Min: 0.639s | Max: 0.857s
GPU memory (allocated): 3707.19 MB ± 3.22 MB
CPU memory (RSS): 1478.48 MB ± 0.00 MB



python eval_latency.py --device cuda --model_family llama --out_seq_len 32 --inp_seq_len 8


Benchmark Results:
--------------------------------------------------

llama:
Mean latency: 1.485s ± 0.013s
Min: 1.473s | Max: 1.510s
GPU memory (allocated): 26162.93 MB ± 0.00 MB
CPU memory (RSS): 1022.33 MB ± 0.01 MB

llama::cp::rank2::horizon2:
Mean latency: 0.752s ± 0.011s
Min: 0.744s | Max: 0.768s
GPU memory (allocated): 28035.36 MB ± 0.00 MB
CPU memory (RSS): 1118.24 MB ± 0.02 MB

llama::cp::rank4::horizon4:
Mean latency: 0.403s ± 0.010s
Min: 0.398s | Max: 0.425s
GPU memory (allocated): 33970.34 MB ± 0.00 MB
CPU memory (RSS): 1125.05 MB ± 0.05 MB