   6544201  CANCELLED+*                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 1024  --horizon 2 --horizon_eval 2 --rank 2
1   6544206  CANCELLED+*                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 2048  --horizon 2 --horizon_eval 2 --rank 2
2   6544208  CANCELLED+*                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 1280  --horizon 2 --horizon_eval 2 --rank 2
3   6544215  CANCELLED+*                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 4096 --horizon 2 --horizon_eval 2 --rank 2
4   6546543   COMPLETED*                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 4096 --horizon 2 --horizon_eval 2 --rank 8
5   6544224      PENDING                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 1024 --horizon 2 --horizon_eval 2 --rank 8
6   6544225       FAILED                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 1280 --horizon 2 --horizon_eval 2 --rank 8
7   6544227    COMPLETED                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 2048 --horizon 2 --horizon_eval 2 --rank 8
8   6549067   COMPLETED*   python scripts/eval_acc.py -c checkpoints/e50_bs8_sl128_l1e-05_ws100_gcv1.0_mtllama7b_mhcp_hd4096_nl1_r8_h2_pfexp_imrandom_tmlora_lr32_umelFalse_he2_mnt128_tk200_nb1_gv3_dgsm8k_ttword_s42_lsepoch_lo1_esepoch_ev1_gsepoch_ge1000_mns68000_eoFalse_caFalse_abs1_wi7c860a4b
9   6549655      TIMEOUT                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 5120 --horizon 2 --horizon_eval 2 --rank 8
10  6550242      TIMEOUT                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 5120 --horizon 2 --horizon_eval 2 --rank 8
11  6553652      TIMEOUT   python scripts/eval_acc.py -c checkpoints/e50_bs8_sl128_l1e-05_ws100_gcv1.0_mtllama7b_mhcp_hd5120_nl1_r8_h2_pfexp_imrandom_tmlora_lr32_umelFalse_he2_mnt128_tk200_nb1_gv3_dgsm8k_ttword_s42_lsepoch_lo1_esepoch_ev1_gsepoch_ge1000_mns68000_eoFalse_caFalse_abs1_wifaa14ed0
12  6553807       FAILED  python scripts/eval_acc.py -c checkpoints/e50_bs8_sl128_l1e-05_ws100_gcv1.0_mtllama7b_mhcp_hd5120_nl1_r8_h2_pfexp_imrandom_tmlora_lr32_umelFalse_he2_mnt128_tk200_nb1_gv3_dgsm8k_ttword_s42_lsepoch_lo1_esepoch_ev1_gsepoch_ge1000_mns68000_eoFalse_caFalse_abs1_wifaa14ed0
13  6556723      FAILED*                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 5120 --horizon 2 --horizon_eval 2 --rank 32
14  6555173      RUNNING                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 5120 --horizon 2 --horizon_eval 2 --rank 16
15  6562309     TIMEOUT*                             accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 4 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 5120 --horizon 2 --horizon_eval 2 --rank 32
16  6563816  OUT_OF_ME+*                              accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 8192 --horizon 2 --horizon_eval 2 --rank 8
17  6558357      RUNNING   python scripts/eval_acc.py -c checkpoints/e50_bs8_sl128_l1e-05_ws100_gcv1.0_mtllama7b_mhcp_hd2048_nl1_r8_h2_pfexp_imrandom_tmlora_lr32_umelFalse_he2_mnt128_tk200_nb1_gv3_dgsm8k_ttword_s42_lsepoch_lo1_esepoch_ev1_gsepoch_ge1000_mns68000_eoFalse_caFalse_abs1_wi017e28c8
18  6568935     PENDING*  accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 8192 --horizon 2 --horizon_eval 2 --rank 8 --use_memory_efficient_loss
19  6566580      TIMEOUT   python scripts/eval_acc.py -c checkpoints/e50_bs8_sl128_l1e-05_ws100_gcv1.0_mtllama7b_mhcp_hd8192_nl1_r8_h2_pfexp_imrandom_tmlora_lr32_umelFalse_he2_mnt128_tk200_nb1_gv3_dgsm8k_ttword_s42_lsepoch_lo1_esepoch_ev1_gsepoch_ge1000_mns68000_eoFalse_caFalse_abs1_wi28dbce6b
20  6566919    COMPLETED  python scripts/eval_acc.py -c checkpoints/e50_bs8_sl128_l1e-05_ws100_gcv1.0_mtllama7b_mhcp_hd8192_nl1_r8_h2_pfexp_imrandom_tmlora_lr32_umelFalse_he2_mnt128_tk200_nb1_gv3_dgsm8k_ttword_s42_lsepoch_lo1_esepoch_ev1_gsepoch_ge1000_mns68000_eoFalse_caFalse_abs1_wi28dbce6b
21  6568942      SUBMIT*                           accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset sharegpt --model llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --hidden_dim 5120 --horizon 2 --horizon_eval 2 --rank 8