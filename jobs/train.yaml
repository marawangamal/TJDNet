config:
  user: marawan.gamal # your username to check slurm status
  max_jobs: 10 # maximum number of jobs to run in parallel
  max_gpus: 10 # maximum number of GPUs to use in parallel

common_preamble_declarations:
  - "#!/bin/bash"
  - "#SBATCH --output=slurm/slurm-%j.out"
  - "#SBATCH --error=slurm/slurm-error-%j.out"

common_preamble_runs:
  # 1. Load the required modules
  - module load python/3.9

  # 2. Load your environment
  - source /home/mila/m/marawan.gamal/scratch/TJDNet/.venv/bin/activate

  # # 3. Copy your dataset on the compute node
  # - cp -r /home/mila/m/marawan.gamal/.cache/huggingface $SLURM_TMPDIR/huggingface

groups:
  - name: gsm8k
    preamble:
      - "#SBATCH --partition=short-unkillable"
      - "#SBATCH --gres=gpu:a100l:4"
      - "#SBATCH --cpus-per-task=12"
      - "#SBATCH --mem=128G"
      - "#SBATCH --nodes=1"
      - "#SBATCH --time=3:00:00"

    paralleljobs:
      # baseline
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head base
      # CP (h=2, nl=2, rank=2:32)
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 2
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 4
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 8
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 16
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 32
      # CP (h=3, nl=2, rank=2:32)
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 3 --horizon_eval 3 --rank 2
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 3 --horizon_eval 3 --rank 4
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 3 --horizon_eval 3 --rank 8
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 3 --horizon_eval 3 --rank 16
      - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 3 --horizon_eval 3 --rank 32
      # # CP (h=4, nl=2, rank=2:32)
      # - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 4 --horizon_eval 4 --rank 2
      # - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 4 --horizon_eval 4 --rank 4
      # - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 4 --horizon_eval 4 --rank 8
      # - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 4 --horizon_eval 4 --rank 16
      # - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset gsm8k --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 4 --horizon_eval 4 --rank 32

  # - name: sharegpt
  #   preamble:
  #     - "#SBATCH --partition=long"
  #     - "#SBATCH --gres=gpu:a100l:4"
  #     - "#SBATCH --cpus-per-task=12"
  #     - "#SBATCH --mem=128G"
  #     - "#SBATCH --nodes=1"
  #     - "#SBATCH --time=24:00:00"

  #   paralleljobs:
  #     # baseline
  #     - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset sharegpt --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head base --compute_acc
  #     # CP (h=2, nl=2, rank=2:32)
  #     - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset sharegpt --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 16
  #     - accelerate launch --use_fsdp --config_file configs/fsdp/fsdp_4gpus.yaml train.py --dataset sharegpt --model_type llama7b --epochs 50 --batch_size 8 --seq_len 128 --lr 1e-5 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 32


  # - name: stemp
  #   preamble:
  #     - "#SBATCH --partition=short-unkillable"
  #     - "#SBATCH --gres=gpu:2"
  #     - "#SBATCH --mem=32G"
  #     - "#SBATCH --nodes=1"
  #   paralleljobs:
  #     # Base
  #     - python train.py --dataset stemp --model_type gpt2 --epochs 10 --batch_size 32 --seq_len 256 --lr 1e-4 --model_head base --compute_acc
  #     # CP
  #     - python train.py --dataset stemp --model_type gpt2 --epochs 10 --batch_size 32 --seq_len 256 --lr 1e-4 --model_head cp --num_layers 2 --hidden_dim 768  --horizon 2 --horizon_eval 2 --rank 2